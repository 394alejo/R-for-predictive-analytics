{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensambles de modelos\n",
    "===\n",
    "\n",
    "**Juan David Velásquez Henao**  \n",
    "jdvelasq@unal.edu.co   \n",
    "Universidad Nacional de Colombia, Sede Medellín  \n",
    "Facultad de Minas  \n",
    "Medellín, Colombia\n",
    "\n",
    "---\n",
    "\n",
    "Haga click [aquí](https://github.com/jdvelasq/machine-learning/blob/master/01-archivos-y-directorios.ipynb) para acceder a la última versión online.\n",
    "\n",
    "Haga click [aquí](http://nbviewer.jupyter.org/github/jdvelasq/machine-learning/blob/master/01-archivos-y-directorios.ipynb) para ver la última versión online en `nbviewer`. \n",
    "\n",
    "---\n",
    "[Licencia](https://github.com/jdvelasq/machine-learning/blob/master/LICENCIA.txt)  \n",
    "[Readme](https://github.com/jdvelasq/machine-learning/blob/master/readme.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición del problema real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se desea construir un esquema de pronóstico que permita aprovechar la información capturada por muchos modelos diferentes construidos sobre los mismos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Definición del problema en términos de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Si se tienen múltiples pronósticos obtenidos por diferentes modelos para los mismos datos, se mejor simplemente seleccionar el mejor mejor modelo y descartar la demás información, o se pueden aprovechar dichos pronósticos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un ensamble es un tipo de modelo que permite la combinación de varios modelos de predicción para obtener un solo pronóstico basado en los pronósticos individuales de cada modelo. En la figura siguiente se presenta un esquema ilustrativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/combiner.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clave de la operación de esta metodología se basa en la diversidad, la cual puede obtenerse de diferentes formas:\n",
    "\n",
    "* Variando los datos de entrenamiento: se usa el mismo modelo en todos los casos, pero para cada uno de ellos se usa una muestra de entrenamiento obtenida por boostraping; así cada modelo tiene parámetros diferentes\n",
    "\n",
    "\n",
    "* Variando la configuración del modelo: se usan exactamente los mismos datos de entrenamiento, pero sobre diferentes modelos obtenidos variando su configuración, por ejemplo mismo modelo pero con diferente configuración (entradas usadas, complejidad, etc). Inclusive se pueden utilizar distintos modelos.\n",
    "\n",
    "\n",
    "* Una combinación de los dos anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El combinador es un mecanismo que obtiene un único pronóstico a partir de los pronósticos individuales de cada modelo. Para problemas de clasificación, la convinación se hace por votación. En problemas de regresión, mediante promedio simple, promedio combinado o, inclusive, regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferentes metodologías se han desarrollado sobre este concepto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging (Bootstrap aggregation)\n",
    "\n",
    "En esta metodología la diversidad se obtiene al entrenar un mismo modelo sobre diferentes conjuntos de entrenamiento usando bootstrap. La combinación se hace por votación para problemas de clasificación y por promedio para problemas numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/yq/svn60mh123z6dzr3d4rjk_740000gn/T//Rtmp4KXWMk/downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "# install.packages(\"ipred\")\n",
    "library(ipred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           \n",
       "credit_pred  No Yes\n",
       "        No  700   0\n",
       "        Yes   0 300"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# crea 25 arboles de decisión\n",
    "credit <- read.csv(\"data/credit.csv\")\n",
    "credit$default <- factor(credit$default, labels=c(\"No\", \"Yes\"))\n",
    "mybag <- bagging(default ~ ., data = credit, nbagg = 25)\n",
    "credit_pred <- predict(mybag, credit)\n",
    "table(credit_pred, credit$default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: lattice\n",
      "Loading required package: ggplot2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Bagged CART \n",
       "\n",
       "1000 samples\n",
       "  20 predictor\n",
       "   2 classes: 'No', 'Yes' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 900, 900, 900, 900, 900, 900, ... \n",
       "Resampling results:\n",
       "\n",
       "  Accuracy  Kappa  \n",
       "  0.746     0.36038\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Para evaluar realmente la precisión del modelo\n",
    "# se usa crossvalidation\n",
    "library(caret)\n",
    "set.seed(300)\n",
    "ctrl <- trainControl(method = \"cv\", number = 10)\n",
    "train(default ~ ., data = credit, method = \"treebag\", trControl = ctrl)\n",
    "# note que tiene un desempeño muy similar al metodo C5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoosting (Adaptive Boosting)\n",
    "\n",
    "En este caso, los conjuntos de dato son diseñados especificamente para generar modelos complementarios. De forma simplificada, el algoritmo procede de la siguiente forma:\n",
    "\n",
    "* Paso 1: Se construye un clasificador sobre todos los datos de entrenamiento.\n",
    "\n",
    "\n",
    "* Paso 2: Se construye un nuevo conjunto de datos con los ejemplos mal clasificados (o una porción de ellos).\n",
    "\n",
    "\n",
    "* Paso 3: se construye un nuevo clasificador con los datos obtenidos en el paso 2.\n",
    "\n",
    "\n",
    "* Paso 4: Se retorna al Paso 2.\n",
    "\n",
    "\n",
    "El proceso itera hasta que se alcanza una precisión requerida o el número máximo de clasificadores permitidos en el ensamble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: rpart\n",
      "Loading required package: foreach\n",
      "Loading required package: doParallel\n",
      "Loading required package: iterators\n",
      "Loading required package: parallel\n",
      "\n",
      "Attaching package: ‘adabag’\n",
      "\n",
      "The following object is masked from ‘package:ipred’:\n",
      "\n",
      "    bagging\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "               Observed Class\n",
       "Predicted Class  No Yes\n",
       "            No  700   0\n",
       "            Yes   0 300"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# install.packages(\"adabag\")\n",
    "library(adabag)\n",
    "set.seed(300)\n",
    "m_adaboost <- boosting(default ~ ., data = credit)\n",
    "p_adaboost <- predict(m_adaboost, credit)\n",
    "p_adaboost$confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:  1 Sun Mar  4 09:58:05 2018 \n",
      "i:  2 Sun Mar  4 09:58:39 2018 \n",
      "i:  3 Sun Mar  4 09:59:13 2018 \n",
      "i:  4 Sun Mar  4 09:59:47 2018 \n",
      "i:  5 Sun Mar  4 10:00:21 2018 \n",
      "i:  6 Sun Mar  4 10:00:56 2018 \n",
      "i:  7 Sun Mar  4 10:01:31 2018 \n",
      "i:  8 Sun Mar  4 10:02:07 2018 \n",
      "i:  9 Sun Mar  4 10:02:43 2018 \n",
      "i:  10 Sun Mar  4 10:03:18 2018 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "               Observed Class\n",
       "Predicted Class  No Yes\n",
       "            No  594 153\n",
       "            Yes 106 147"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# verificación usando CV\n",
    "set.seed(300)\n",
    "adaboost_cv <- boosting.cv(default ~ ., data = credit)\n",
    "adaboost_cv$confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: grid\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "            value     ASE     z Pr(>|z|)\n",
       "Unweighted 0.3544 0.03237 10.95 6.68e-28\n",
       "Weighted   0.3544 0.03237 10.95 6.68e-28"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# install.packages(\"vcd\")\n",
    "library(vcd)\n",
    "Kappa(adaboost_cv$confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest\n",
    "\n",
    "En este método se combinan el bagging con la selección aleatoria de caracteríticas para aumetar la diversidad. La salida del modelo se obtiene por votación. Cada ejemplo que no es considerado durante el entrenamiento es usado como parte del conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "randomForest 4.6-12\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "Attaching package: ‘randomForest’\n",
      "\n",
      "The following object is masked from ‘package:ggplot2’:\n",
      "\n",
      "    margin\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       " randomForest(formula = default ~ ., data = credit) \n",
       "               Type of random forest: classification\n",
       "                     Number of trees: 500\n",
       "No. of variables tried at each split: 4\n",
       "\n",
       "        OOB estimate of  error rate: 22.7%\n",
       "Confusion matrix:\n",
       "     No Yes class.error\n",
       "No  649  51  0.07285714\n",
       "Yes 176 124  0.58666667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# install.packages(\"randomForest\")\n",
    "library(randomForest)\n",
    "set.seed(300)\n",
    "# por defecto crea un ensamble de 500 arboles\n",
    "# que consideran la raiz cuadrada de la cantidad\n",
    "# de atributos presentes en el conjunto de entrenamiento\n",
    "rf <- randomForest(default ~ ., data = credit)\n",
    "rf\n",
    "# en la salida OOB se refiere a out-of-bag error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A continuación se comparan los resultados de \n",
    "# random forest (rf) con C5.0 \n",
    "library(caret)\n",
    "# parametros de control\n",
    "ctrl <- trainControl(method = \"repeatedcv\",\n",
    "                     number = 10, \n",
    "                     repeats = 10)\n",
    "# malla de parametros a considerar\n",
    "grid_rf <- expand.grid(.mtry = c(2, 4, 8, 16))\n",
    "set.seed(300)\n",
    "m_rf <- train(default ~ ., \n",
    "              data = credit, \n",
    "              method = \"rf\",\n",
    "              metric = \"Kappa\", \n",
    "              trControl = ctrl,\n",
    "              tuneGrid = grid_rf)\n",
    "m_rf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# comparación con un boosted tree\n",
    "grid_c50 <- expand.grid(.model = \"tree\",\n",
    "                        .trials = c(10, 20, 30, 40),\n",
    "                        .winnow = \"FALSE\")\n",
    "set.seed(300)\n",
    "m_c50 <- train(default ~ ., \n",
    "               data = credit, \n",
    "               method = \"C5.0\",\n",
    "               metric = \"Kappa\", \n",
    "               trControl = ctrl,\n",
    "               tuneGrid = grid_c50)\n",
    "m_c50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio.--** Cuál de los dos modelos anteriores fue mejor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  },
  "nteract": {
   "version": "0.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
