{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partición de los datos\n",
    "===\n",
    "\n",
    "**Juan David Velásquez Henao**  \n",
    "jdvelasq@unal.edu.co   \n",
    "Universidad Nacional de Colombia, Sede Medellín  \n",
    "Facultad de Minas  \n",
    "Medellín, Colombia\n",
    "\n",
    "---\n",
    "\n",
    "Haga click [aquí](https://github.com/jdvelasq/predictive-analytics/blob/master/09-R-data-partition.ipynb) para acceder a la última versión online.\n",
    "\n",
    "Haga click [aquí](http://nbviewer.jupyter.org/github/jdvelasq/predictive-analytics/blob/master/09-R-data-partition.ipynb) para ver la última versión online en `nbviewer`. \n",
    "\n",
    "---\n",
    "[Licencia](https://github.com/jdvelasq/predictive-analytics/blob/master/LICENSE)  \n",
    "[Readme](https://github.com/jdvelasq/predictive-analytics/blob/master/readme.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición del problema real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el tutorial anterior se construyó un clasificador que tiene como objetivo reprobar o aprobar solicitudes de crédito. El gerente de proyecto ha solitado que se haga un análisis del desempeño del sistema cuando se encuentre en productivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición del problema en términos de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema radica en que los datos para entrenamiento y prueba fueron tomados de forma determinística, pero los resultados del desempeño del clasificador podrían variar si la partición de los datos se hace diferente. Más aún, en vez de realizar estimaciones puntuales de la métrica de error seleccionada, sería mucho más conveniente estimar su distribución de probabilidades. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Se carga la librería\n",
    "library(C50)\n",
    "\n",
    "## Lectura de los datos\n",
    "credit <- read.csv(\"data/credit.csv\")\n",
    "credit$default <- factor(credit$default, labels=c(\"No\", \"Yes\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se presentan los casos de análisis cuya complejidad aumenta de forma progresiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso 1 - Selección determinística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " int [1:900] 1 2 3 4 5 6 7 8 9 10 ...\n"
     ]
    }
   ],
   "source": [
    "## Se toman los primero 900 datos para entrenamiento\n",
    "## y los 100 últimos para prueba\n",
    "train_sample <- 1:900\n",
    "str(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "34"
      ],
      "text/latex": [
       "34"
      ],
      "text/markdown": [
       "34"
      ],
      "text/plain": [
       "[1] 34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Se entrena el modelo y se prueba\n",
    "credit_train <- credit[train_sample, ]\n",
    "credit_test  <- credit[-train_sample, ]\n",
    "credit_model <- C5.0(credit_train[-17], credit_train$default)\n",
    "credit_pred <- predict(credit_model, credit_test)\n",
    "length(credit_test$default[credit_pred != credit_test$default])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     credit_pred\n",
       "      No Yes\n",
       "  No  54  14\n",
       "  Yes 20  12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## métricas de error\n",
    "table(credit_test$default, credit_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso 2 - Selección aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " int [1:900] 721 875 760 884 455 166 324 506 722 981 ...\n"
     ]
    }
   ],
   "source": [
    "## cuál es el resultado si las muestras de entrenamiento\n",
    "## y prueba son seleccionadas aleatoriamente?\n",
    "set.seed(12345)   # se reinicia la semilla del generador aleatorio\n",
    "train_sample <- sample(1000, 900)\n",
    "str(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "26"
      ],
      "text/latex": [
       "26"
      ],
      "text/markdown": [
       "26"
      ],
      "text/plain": [
       "[1] 26"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## entrenamiento y pronóstico\n",
    "credit_train <- credit[train_sample, ]\n",
    "credit_test  <- credit[-train_sample, ]\n",
    "credit_model <- C5.0(credit_train[-17], credit_train$default)\n",
    "credit_pred <- predict(credit_model, credit_test)\n",
    "length(credit_test$default[credit_pred != credit_test$default])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     credit_pred\n",
       "      No Yes\n",
       "  No  59  14\n",
       "  Yes 12  15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Métricas de error.\n",
    "## Note que el error calculado cambio.\n",
    "## Es decir, las métricas son una cantidad aleatoria\n",
    "## y varia de acuerdo a como se haga la partición\n",
    "table(credit_test$default, credit_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso 3 - Validación cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observó en las dos soluciones anteriores, los resultados varían de acuerdo a como se partan los datos; más aún, no hay información sobre el desempeño real de un modelo en producción. En la práctica, los datos se suelen partir en tres conjuntos, tal como muestra la gráfica de abajo:\n",
    "\n",
    "\n",
    "* Conjunto de calibración de parámetros del modelo.\n",
    "\n",
    "\n",
    "* Conjunto de prueba, usado comunmente para determinar la complejidad del modelo o el valor óptimo de alguno de sus parámetros.\n",
    "\n",
    "\n",
    "* Conjunto de pronóstico, en el que se intenta reproducir el comportamiento del modelo en productivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/data-partition.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los casos 1 y 2 se dividio el conjunto de datos únicamente en los conjuntos de calibración y prueba. En el Caso 1 se realizó la partición de forma secuencial, tal como se presenta en la figura anterior, mientras que en el Caso 2 se realizó la partición de forma aleatoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se tiene en cuenta que hay muchas particiones aleatorias posibles, una mejor estimación de la matriz de confusión (o cualquier otro estadístico que se calcule para un conjunto de datos) podría ser tomando los valores esperados de cada métrica. Es decir, si se repite el experimento $N$ veces, se tendrían $N$ valores posibles para cada uno de los elementos de la matriz de confusión y por lo tanto se podría tener su valor medio. Esta sería una métrica mucho más apropiada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, este método no funciona muy bien porque el mismo conjunto de patrones podría aparecer repetido muchas veces, llevando a estimaciones erróneas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio.--** Explique la afirmación anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso 4 - Bootstrap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El bootstrap se basa en el remuestreo de los datos para poder obtener una muestra del estadístico que se está calculado (por ejemplo, la cantidad de falsos positivos FP). \n",
    "\n",
    "Supoga que tiene una muestra de ocho ejemplos:\n",
    "\n",
    "\n",
    "$$\\{x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8\\}$$\n",
    "\n",
    "Una muestra bootstap se obtiene de la muestra original, seleccionando ocho elementos de forma aleatoria. Por ejemplo, una muestra bootstrap podría ser:\n",
    "\n",
    "$$\\{x_1, x_2, x_2, x_2, x_4, x_1, x_7, x_7\\}$$\n",
    "\n",
    "Nóte que los elementos pueden repetirse. Sobre cada muestra bootstrap obtenida, se realiza el proceso de cómputo y se obtiene el estadístico de interés. Si este procedimiento se repite 500 veces para calcular la cantidad de FP, se tenddrían 500 valores posibles de FP. Una estimación mucho mejor del valor de FP, sería calcular su valor promedio a partir de la muestra de 500 valores. Más aún, podría calcularse el histograma o la distribución de probabilidades de FP, lo cual es mucho más informativo sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio.--** Suponga que $N$ = 100 (cantidad de muestras bootstrap), y calcule los valores promedios para los cuatro elementos de la matriz de confusión (problema de los créditos riesgosos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio.--** Grafique el histograma de frecuencias para cada uno de los elementos de la matriz de transición del ejercicio anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio.--** Cuál es la función (o funciones) del lenguaje R para realizar bootstraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso 5. K-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este método, el conjunto de datos para entrenamiento (ajuste + prueba) es dividido en $K$ grupos. Este es un proceso iterativo que opera de la siguiente forma (véase la figura de abajo). \n",
    "\n",
    "\n",
    "* Se toma el grupo 1 como conjunto de datos de prueba (grupo rojo) y se entrena el modelo con los grupos restantes {2, ..., K} (grupo negro).\n",
    "\n",
    "\n",
    "* Se toma el grupo 2 como conjunto de datos de prueba (grupo rojo) y se entrena el modelo con los grupos restantes {1, 3, ..., K} (grupo negro).\n",
    "\n",
    "\n",
    "* Se continua de esta forma hasta que se usa el grupo K para prueba, mientras que se usan los grupos 1 hasta K-1 para entrenamiento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/k-fold-crossval.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta forma, se tienen K valores posibles para el estadístico de interés. Usualmente se reporta su valor promedio.\n",
    "\n",
    "Note que una mejor opción sería distribuir los datos en cada grupo de forma aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Las librerías irr y caret tienen funciones especializadas\n",
    "## para aplicar esta metodología\n",
    "## install.packages('irr')\n",
    "library(irr)\n",
    "library(caret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "also installing the dependency ‘lpSolve’\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/yq/svn60mh123z6dzr3d4rjk_740000gn/T//Rtmpykflrs/downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: lpSolve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 10\n",
      " $ Fold01: int [1:100] 23 51 85 91 92 97 101 106 125 136 ...\n",
      " $ Fold02: int [1:100] 9 20 26 27 37 41 58 68 76 82 ...\n",
      " $ Fold03: int [1:100] 2 5 6 8 11 13 19 32 34 40 ...\n",
      " $ Fold04: int [1:100] 4 10 28 48 78 83 120 132 134 142 ...\n",
      " $ Fold05: int [1:100] 21 63 74 87 103 107 108 112 119 121 ...\n",
      " $ Fold06: int [1:100] 22 29 31 36 39 42 45 57 59 64 ...\n",
      " $ Fold07: int [1:100] 12 14 17 33 35 43 44 52 62 65 ...\n",
      " $ Fold08: int [1:100] 7 15 16 18 25 46 67 72 84 86 ...\n",
      " $ Fold09: int [1:100] 3 49 50 53 56 60 70 71 98 102 ...\n",
      " $ Fold10: int [1:100] 1 24 30 38 47 61 81 105 109 116 ...\n"
     ]
    }
   ],
   "source": [
    "## se crean 10 grupos\n",
    "folds <- createFolds(credit$default, k = 10)\n",
    "str(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 10\n",
      " $ Fold01: num 0.266\n",
      " $ Fold02: num 0.475\n",
      " $ Fold03: num 0.255\n",
      " $ Fold04: num 0.175\n",
      " $ Fold05: num 0.255\n",
      " $ Fold06: num 0.193\n",
      " $ Fold07: num 0.417\n",
      " $ Fold08: num 0.381\n",
      " $ Fold09: num 0.303\n",
      " $ Fold10: num 0.475\n"
     ]
    }
   ],
   "source": [
    "## Esta variable guarda los resultados para cada uno \n",
    "## de los 10 grupos.\n",
    "## lapply aplica la función especificada a cada uno \n",
    "## de los grupos\n",
    "cv_results <- lapply(folds, function(x) {\n",
    "    \n",
    "    # elimina el grupo del patron de entrenamiento\n",
    "    credit_train <- credit[-x, ]\n",
    "    \n",
    "    # usa el grupo como conjunto de prueba\n",
    "    credit_test <- credit[x, ]\n",
    "    \n",
    "    # entrena el modelo y pronostica\n",
    "    credit_model <- C5.0(default ~ ., data = credit_train)\n",
    "    credit_pred <- predict(credit_model, credit_test)\n",
    "    credit_actual <- credit_test$default\n",
    "    \n",
    "    # calcula una métrica de error\n",
    "    kappa <- kappa2(data.frame(credit_actual, credit_pred))$value\n",
    "    \n",
    "    # retorna el valor calculado\n",
    "    return(kappa)\n",
    "  })\n",
    "\n",
    "# Se calcula kappa para cada uno de los grupos\n",
    "str(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.319543170828383"
      ],
      "text/latex": [
       "0.319543170828383"
      ],
      "text/markdown": [
       "0.319543170828383"
      ],
      "text/plain": [
       "[1] 0.3195432"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Se reporta el promedio de kappa \n",
    "mean(unlist(cv_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio.--** Use este método con K=15 para estimar la distribución de los valores de la matriz de confusión y compare contra los otros métodos presentados.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso 6. Método leave-one-out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es el mismo método anterior con K=1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/leave-one-out.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partición de los datos\n",
    "===\n",
    "\n",
    "**Juan David Velásquez Henao**  \n",
    "jdvelasq@unal.edu.co   \n",
    "Universidad Nacional de Colombia, Sede Medellín  \n",
    "Facultad de Minas  \n",
    "Medellín, Colombia\n",
    "\n",
    "---\n",
    "\n",
    "Haga click [aquí](https://github.com/jdvelasq/predictive-analytics/blob/master/09-R-data-partition.ipynb) para acceder a la última versión online.\n",
    "\n",
    "Haga click [aquí](http://nbviewer.jupyter.org/github/jdvelasq/predictive-analytics/blob/master/09-R-data-partition.ipynb) para ver la última versión online en `nbviewer`. \n",
    "\n",
    "---\n",
    "[Licencia](https://github.com/jdvelasq/predictive-analytics/blob/master/LICENSE)  \n",
    "[Readme](https://github.com/jdvelasq/predictive-analytics/blob/master/readme.md)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  },
  "nteract": {
   "version": "0.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
